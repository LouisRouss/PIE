{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../functions')\n",
    "import data_utilities as data_u\n",
    "import dict_utilities as dict_u\n",
    "import nlp_utilities as nlp_u\n",
    "\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = '../data/'\n",
    "dict_dir = data_folder + 'data_dict.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dict_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers already saved : dict_keys(['google', 'exxon', 'total'])\n",
      "Tickers after reset : dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "import dict_utilities as dict_u\n",
    "\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers already saved : {data_dict.keys()}\")\n",
    "\n",
    "dict_u.reset_dict(dict_dir)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers after reset : {data_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news to data dictionary from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers added : dict_keys(['google', 'exxon'])\n",
      "\n",
      "Number of news in ticker Google : 3608\n"
     ]
    }
   ],
   "source": [
    "import data_utilities as data_u\n",
    "\n",
    "search_words = ['Google', 'Exxon']\n",
    "news_to_read = \"Reuters\"\n",
    "format_cols = [\"Text\", \"Author\", \"Date\"]\n",
    "data_u.add_news_to_dict(search_words, data_folder, news_to_read, dict_dir, format_cols)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers added : {data_dict.keys()}\\n\")\n",
    "print(f\"Number of news in ticker {search_words[0]} : {len(data_dict[search_words[0].lower()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news to data dictionary from Twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers before operation : dict_keys(['google', 'exxon'])\n",
      "\n",
      "Tickers now : dict_keys(['google', 'exxon', 'total'])\n",
      "\n",
      "Number of news in ticker Google : 3708\n"
     ]
    }
   ],
   "source": [
    "date_since = \"2020-11-13\"\n",
    "nb_items = 100\n",
    "language = \"fr\"\n",
    "codes = data_u.get_codes(data_folder + \"twitter_codes.txt\")\n",
    "from_ids = ['Google', 'Total']\n",
    "print(f\"Tickers before operation : {data_dict.keys()}\\n\")\n",
    "data_u.add_tweets_to_dict(date_since, nb_items, language, codes,\\\n",
    "                    format_cols, dict_dir, retweet=False, from_ids=from_ids)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers now : {data_dict.keys()}\\n\")\n",
    "print(f\"Number of news in ticker {search_words[0]} : {len(data_dict[search_words[0].lower()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news to data dictionary from all over Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers before operation : dict_keys(['google', 'exxon', 'total'])\n",
      "\n",
      "Tickers now : dict_keys(['google', 'exxon', 'total', 'facebook'])\n",
      "\n",
      "Number of news in ticker Google : 3808\n"
     ]
    }
   ],
   "source": [
    "date_since = \"2020-11-13\"\n",
    "nb_items = 100\n",
    "language = \"fr\"\n",
    "codes = data_u.get_codes(data_folder + \"twitter_codes.txt\")\n",
    "from_words = ['Google', 'Facebook']\n",
    "print(f\"Tickers before operation : {data_dict.keys()}\\n\")\n",
    "data_u.add_tweets_to_dict(date_since, nb_items, language, codes,\\\n",
    "                    format_cols, dict_dir, retweet=False, from_words=from_words)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers now : {data_dict.keys()}\\n\")\n",
    "print(f\"Number of news in ticker {search_words[0]} : {len(data_dict[search_words[0].lower()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing nlp_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW/TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document - words matrix: (4020, 12978)\n",
      "First words: ['aa', 'aal', 'aba', 'aback', 'abacus', 'abandon', 'abandoned', 'abandonment', 'abate', 'abb', 'abbey', 'abbreviate', 'abdominal', 'abide', 'abiding', 'ability', 'able', 'ably', 'aboard', 'aborted', 'abortion', 'abortive', 'abound', 'abrasive', 'abroad', 'abrupt', 'abruptly', 'absence', 'absent', 'absentee', 'absolute', 'absolutely', 'absorb', 'absorbed', 'absorbing', 'absorption', 'abstain', 'abstract', 'abstractly', 'absurd', 'abu', 'abundance', 'abundant', 'abundantly', 'abuse', 'abuser', 'abusive', 'abuzz', 'abysmal', 'abyss', 'academic', 'academy', 'acca', 'accelerate', 'accelerated', 'acceleration', 'accelerator', 'accelerometer', 'accent', 'accept', 'acceptable', 'acceptance', 'accepted', 'access', 'accessible', 'accession', 'accessory', 'accident', 'accidental', 'accidentally', 'acclaim', 'accommodate', 'accommodating', 'accommodation', 'accommodative', 'accompany', 'accomplish', 'accomplished', 'accord', 'accordance', 'according', 'accordingly', 'accordion', 'account', 'accountability', 'accountable', 'accountancy', 'accountant', 'accounting', 'accredited', 'accretive', 'accrual', 'accrue', 'accumulate', 'accumulation', 'accuracy', 'accurate', 'accurately', 'accusation', 'accuse']\n"
     ]
    }
   ],
   "source": [
    "import nlp_utilities as nlp_u\n",
    "\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "df = data_dict['google']\n",
    "\n",
    "bow, countvect, feat2word = nlp_u.df_to_bow(df, TFIDF=True)\n",
    "\n",
    "print(\"Document - words matrix:\", bow.shape)\n",
    "print(\"First words:\", countvect.get_feature_names()[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('low', 0.7797523140907288),\n",
       " ('hit', 0.7690551280975342),\n",
       " ('record', 0.654312789440155),\n",
       " ('highest', 0.6522954106330872),\n",
       " ('galloping', 0.6289225220680237),\n",
       " ('bullion', 0.6248561143875122),\n",
       " ('mid', 0.615885317325592),\n",
       " ('gold', 0.604141116142273),\n",
       " ('heavy', 0.6038429737091064),\n",
       " ('level', 0.603442907333374)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nlp_u.df_to_vec(df)\n",
    "model.wv.most_similar(positive=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Author_x</th>\n",
       "      <th>Date_x</th>\n",
       "      <th>Author_y</th>\n",
       "      <th>Date_y</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAN FRANCISCO/NEW YORK  (Reuters) - Wall Stree...</td>\n",
       "      <td>[Paul Thomasch, Eric Auchard]</td>\n",
       "      <td>Fri Oct 20, 2006 4:25pm EDT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRANKFURT  (Reuters) - Internet service provid...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sat Oct 21, 2006 2:21pm EDT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW YORK  (Reuters) - U.S. stocks should exten...</td>\n",
       "      <td>[ers, Chris S]</td>\n",
       "      <td>Mon Oct 23, 2006 5:24am EDT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW YORK  (Reuters) - U.S. stocks rallied on M...</td>\n",
       "      <td>[Vivianne Rodrigues]</td>\n",
       "      <td>Mon Oct 23, 2006 5:37pm EDT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES  (Reuters) - Amazon.com on Tuesday...</td>\n",
       "      <td>[ria Sage, Alex]</td>\n",
       "      <td>Tue Oct 24, 2006 7:39pm EDT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>https://t.co/1r1aITGy2l un dernier pour la route?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>jt50manche</td>\n",
       "      <td>2020-11-29 15:58:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>@Microsoft Et Ã§a câ€™est de la rÃ©silience ou ? \\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Jemexprime1</td>\n",
       "      <td>2020-11-29 15:58:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>Horowitz: Ã©tude CDC: 85% des cas de COVID-19 e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>paxipax_heleane</td>\n",
       "      <td>2020-11-29 15:58:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>@readarrt Tape Aubameyang Kroos sur Google tu ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Banalyste</td>\n",
       "      <td>2020-11-29 15:58:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>ğ‘ğ‘œğ‘¢ğ‘  ğ‘ ğ‘œğ‘šğ‘šğ‘’ğ‘  ğ‘Ì€ ğ‘™ğ‘ ğ‘Ÿğ‘’ğ‘â„ğ‘’ğ‘Ÿğ‘â„ğ‘’ ğ‘‘ğ‘’ 12 ğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘ ğ‘¡ğ‘’ğ‘  ğ‘ğ‘œğ‘¢...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>masksingerfl</td>\n",
       "      <td>2020-11-29 15:57:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3808 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     SAN FRANCISCO/NEW YORK  (Reuters) - Wall Stree...   \n",
       "1     FRANKFURT  (Reuters) - Internet service provid...   \n",
       "2     NEW YORK  (Reuters) - U.S. stocks should exten...   \n",
       "3     NEW YORK  (Reuters) - U.S. stocks rallied on M...   \n",
       "4     LOS ANGELES  (Reuters) - Amazon.com on Tuesday...   \n",
       "...                                                 ...   \n",
       "3803  https://t.co/1r1aITGy2l un dernier pour la route?   \n",
       "3804  @Microsoft Et Ã§a câ€™est de la rÃ©silience ou ? \\...   \n",
       "3805  Horowitz: Ã©tude CDC: 85% des cas de COVID-19 e...   \n",
       "3806  @readarrt Tape Aubameyang Kroos sur Google tu ...   \n",
       "3807  ğ‘ğ‘œğ‘¢ğ‘  ğ‘ ğ‘œğ‘šğ‘šğ‘’ğ‘  ğ‘Ì€ ğ‘™ğ‘ ğ‘Ÿğ‘’ğ‘â„ğ‘’ğ‘Ÿğ‘â„ğ‘’ ğ‘‘ğ‘’ 12 ğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘ ğ‘¡ğ‘’ğ‘  ğ‘ğ‘œğ‘¢...   \n",
       "\n",
       "                           Author_x                       Date_x Author_y  \\\n",
       "0     [Paul Thomasch, Eric Auchard]  Fri Oct 20, 2006 4:25pm EDT      NaN   \n",
       "1                                []  Sat Oct 21, 2006 2:21pm EDT      NaN   \n",
       "2                    [ers, Chris S]  Mon Oct 23, 2006 5:24am EDT      NaN   \n",
       "3              [Vivianne Rodrigues]  Mon Oct 23, 2006 5:37pm EDT      NaN   \n",
       "4                  [ria Sage, Alex]  Tue Oct 24, 2006 7:39pm EDT      NaN   \n",
       "...                             ...                          ...      ...   \n",
       "3803                            NaN                          NaN      NaN   \n",
       "3804                            NaN                          NaN      NaN   \n",
       "3805                            NaN                          NaN      NaN   \n",
       "3806                            NaN                          NaN      NaN   \n",
       "3807                            NaN                          NaN      NaN   \n",
       "\n",
       "     Date_y           Author                Date  \n",
       "0       NaT              NaN                 NaT  \n",
       "1       NaT              NaN                 NaT  \n",
       "2       NaT              NaN                 NaT  \n",
       "3       NaT              NaN                 NaT  \n",
       "4       NaT              NaN                 NaT  \n",
       "...     ...              ...                 ...  \n",
       "3803    NaT       jt50manche 2020-11-29 15:58:57  \n",
       "3804    NaT      Jemexprime1 2020-11-29 15:58:55  \n",
       "3805    NaT  paxipax_heleane 2020-11-29 15:58:12  \n",
       "3806    NaT        Banalyste 2020-11-29 15:58:11  \n",
       "3807    NaT     masksingerfl 2020-11-29 15:57:51  \n",
       "\n",
       "[3808 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic models : LDA and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA model (tf features)\n",
      "Topics in tf-LDA model:\n",
      "Topic #0: percent said new stock year york company dow rose market index content billion time yahoo high medium higher video average\n",
      "Topic #1: said video web new site year also medium clip journal york yahoo advertising deal time music service company content last\n",
      "Topic #2: said percent company new apple year billion yahoo market million would stock quarter also search business time last could one\n",
      "Topic #3: percent billion said stock web company cash new year fell market would index growth week also york average last high\n",
      "Topic #4: said percent new yahoo year web company stock billion quarter search million business advertising mobile video york also share system\n",
      "\n",
      "Fitting LDA model (BOW features)\n",
      "Topics in BOW-LDA model:\n",
      "Topic #0: noble energy nook wind solar grid power electric duke smart gas toy oil book bookstore electricity renewable gold project lan\n",
      "Topic #1: said court patent case commission government information federal law district legal trial could antitrust judge would also statement search eu\n",
      "Topic #2: percent said company yahoo billion year stock quarter new million market revenue would share time deal business search last also\n",
      "Topic #3: tax tiger income rate country pandora corporate viking car house child fund city russia avoidance omega budget minister staff worth\n",
      "Topic #4: said apple new company mobile market rim would china year android phone also one blackberry million world technology could service\n",
      "\n",
      "Fitting NMF model\n",
      "Topics in NMF model:\n",
      "Topic #0: percent stock index dow rose earnings fell average week bank york market day new oil industrial daily exchange billion gain\n",
      "Topic #1: yahoo search deal said advertising offer web board company yang would bid partnership source corp percent stake share billion medium\n",
      "Topic #2: apple said mobile company new phone market android would china million could one also service web technology patent time world\n",
      "Topic #3: rim blackberry playbook motion android company tablet launch device research said operating system share torch security frank market canada analyst\n",
      "Topic #4: quarter revenue percent billion share million year per profit growth earnings said analyst net company forecast street fourth advertising business\n"
     ]
    }
   ],
   "source": [
    "import nlp_utilities as nlp_u\n",
    "\n",
    "#Fresh start\n",
    "search_words = ['Google', 'Exxon']\n",
    "news_to_read = \"Reuters\"\n",
    "format_cols = [\"Text\", \"Author\", \"Date\"]\n",
    "dict_u.reset_dict(dict_dir)\n",
    "data_u.add_news_to_dict(search_words, data_folder, news_to_read, dict_dir, format_cols)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "\n",
    "df = data_dict['google']\n",
    "n_words = 20\n",
    "\n",
    "#LDA\n",
    "print(\"Fitting LDA model (tf features)\")\n",
    "lda, countvect, feat2word = nlp_u.df_to_lda(df, n_topics = 5, TF = True)\n",
    "feature_names = countvect.get_feature_names()\n",
    "\n",
    "print(\"Topics in tf-LDA model:\")\n",
    "nlp_u.print_topics(lda, feature_names, n_words)\n",
    "\n",
    "print(\"\\nFitting LDA model (BOW features)\")\n",
    "lda, countvect, feat2word = nlp_u.df_to_lda(df, n_topics = 5, TF = False)\n",
    "feature_names = countvect.get_feature_names()\n",
    "\n",
    "print(\"Topics in BOW-LDA model:\")\n",
    "nlp_u.print_topics(lda, feature_names, n_words)\n",
    "\n",
    "#NMF\n",
    "print(\"\\nFitting NMF model\")\n",
    "nmf, countvect, feat2word = nlp_u.df_to_nmf(df, n_topics = 5)\n",
    "feature_names = countvect.get_feature_names()\n",
    "\n",
    "print(\"Topics in NMF model:\")\n",
    "nlp_u.print_topics(nmf, feature_names, n_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
